{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dacdc93c-279b-4f17-9e25-94a9a561175b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: nomic[local]\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U langchain_community tiktoken langchainhub scikit-learn langchain langgraph tavily-python  nomic[local] langchain-nomic langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b35a6242",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U langchain-nomic langchain_community tiktoken langchainhub chromadb langchain langgraph nomic[local]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "332e16cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langgraph in /Users/apple/Library/Python/3.9/lib/python/site-packages (0.2.67)\n",
      "Requirement already satisfied: python-dotenv in /Users/apple/Library/Python/3.9/lib/python/site-packages (1.0.1)\n",
      "Requirement already satisfied: langchain in /Users/apple/Library/Python/3.9/lib/python/site-packages (0.3.15)\n",
      "Requirement already satisfied: langchain-openai in /Users/apple/Library/Python/3.9/lib/python/site-packages (0.3.2)\n",
      "Requirement already satisfied: langchain-nomic in /Users/apple/Library/Python/3.9/lib/python/site-packages (0.1.4)\n",
      "Requirement already satisfied: langchain-community in /Users/apple/Library/Python/3.9/lib/python/site-packages (0.3.15)\n",
      "Requirement already satisfied: langchain-core in /Users/apple/Library/Python/3.9/lib/python/site-packages (0.3.31)\n",
      "Requirement already satisfied: openai in /Users/apple/Library/Python/3.9/lib/python/site-packages (1.60.1)\n",
      "Requirement already satisfied: chromadb in /Users/apple/Library/Python/3.9/lib/python/site-packages (0.6.3)\n",
      "Requirement already satisfied: typing-extensions in /Users/apple/Library/Python/3.9/lib/python/site-packages (4.12.2)\n",
      "Requirement already satisfied: pydantic in /Users/apple/Library/Python/3.9/lib/python/site-packages (2.10.6)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from langgraph) (2.0.10)\n",
      "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from langgraph) (0.1.51)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from langchain) (2.0.37)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from langchain) (3.11.11)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from langchain) (0.3.5)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from langchain) (0.3.1)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from langchain-openai) (0.8.0)\n",
      "Requirement already satisfied: nomic<4.0.0,>=3.1.2 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from langchain-nomic) (3.4.1)\n",
      "Requirement already satisfied: pillow<11.0.0,>=10.3.0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from langchain-nomic) (10.4.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from langchain-community) (2.7.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from langchain-core) (24.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /Users/apple/Library/Python/3.9/lib/python/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: build>=1.0.3 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from chromadb) (0.7.6)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from chromadb) (0.115.7)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from chromadb) (3.10.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from chromadb) (1.19.2)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from chromadb) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from chromadb) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from chromadb) (0.50b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from chromadb) (1.29.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from chromadb) (0.21.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /Users/apple/Library/Python/3.9/lib/python/site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from chromadb) (1.70.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from chromadb) (4.2.1)\n",
      "Requirement already satisfied: typer>=0.9.0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from chromadb) (0.15.1)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from chromadb) (32.0.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from chromadb) (5.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from chromadb) (3.10.15)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from chromadb) (13.9.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from pydantic) (2.27.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: pyproject_hooks in /Users/apple/Library/Python/3.9/lib/python/site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from build>=1.0.3->chromadb) (8.5.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from build>=1.0.3->chromadb) (2.2.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from fastapi>=0.95.2->chromadb) (0.45.3)\n",
      "Requirement already satisfied: certifi in /Users/apple/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/apple/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (1.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /Users/apple/Library/Python/3.9/lib/python/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.1.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: click in /Users/apple/Library/Python/3.9/lib/python/site-packages (from nomic<4.0.0,>=3.1.2->langchain-nomic) (8.1.8)\n",
      "Requirement already satisfied: jsonlines in /Users/apple/Library/Python/3.9/lib/python/site-packages (from nomic<4.0.0,>=3.1.2->langchain-nomic) (4.0.0)\n",
      "Requirement already satisfied: loguru in /Users/apple/Library/Python/3.9/lib/python/site-packages (from nomic<4.0.0,>=3.1.2->langchain-nomic) (0.7.3)\n",
      "Requirement already satisfied: pandas in /Users/apple/Library/Python/3.9/lib/python/site-packages (from nomic<4.0.0,>=3.1.2->langchain-nomic) (2.2.3)\n",
      "Requirement already satisfied: pyarrow in /Users/apple/Library/Python/3.9/lib/python/site-packages (from nomic<4.0.0,>=3.1.2->langchain-nomic) (19.0.0)\n",
      "Requirement already satisfied: pyjwt in /Users/apple/Library/Python/3.9/lib/python/site-packages (from nomic<4.0.0,>=3.1.2->langchain-nomic) (2.10.1)\n",
      "Requirement already satisfied: coloredlogs in /Users/apple/Library/Python/3.9/lib/python/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /Users/apple/Library/Python/3.9/lib/python/site-packages (from onnxruntime>=1.14.1->chromadb) (25.1.24)\n",
      "Requirement already satisfied: protobuf in /Users/apple/Library/Python/3.9/lib/python/site-packages (from onnxruntime>=1.14.1->chromadb) (5.29.3)\n",
      "Requirement already satisfied: sympy in /Users/apple/Library/Python/3.9/lib/python/site-packages (from onnxruntime>=1.14.1->chromadb) (1.13.3)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.17)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.66.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.29.0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.29.0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.50b0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.50b0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.50b0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from opentelemetry-instrumentation==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
      "Requirement already satisfied: asgiref~=3.0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from opentelemetry-instrumentation-asgi==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from tokenizers>=0.13.2->chromadb) (0.27.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.4)\n",
      "Requirement already satisfied: websockets>=10.4 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from importlib-resources->chromadb) (3.21.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: filelock in /Users/apple/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.12.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from pandas->nomic<4.0.0,>=3.1.2->langchain-nomic) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from pandas->nomic<4.0.0,>=3.1.2->langchain-nomic) (2025.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langgraph python-dotenv langchain langchain-openai langchain-nomic langchain-community langchain-core openai chromadb typing-extensions pydantic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "add050df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"56d5b24c-9cb7-4ef8-9f52-e7fd9a5f3d5c\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c70623f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"NOMIC_API_KEY\"):\n",
    "    os.environ[\"NOMIC_API_KEY\"] = getpass.getpass(\"Enter your Nomic API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78158869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nk-f9fOyB1TiYAMOw0Y6wB_Wvzn2xwm0B0x6Rc6Wdu6XCw\n"
     ]
    }
   ],
   "source": [
    "print(os.getenv(\"NOMIC_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "367601ef-af82-4361-9733-49963cce7ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling ff82381e2bea... 100% ▕████████████████▏ 4.1 GB                         \n",
      "pulling 43070e2d4e53... 100% ▕████████████████▏  11 KB                         \n",
      "pulling 491dfa501e59... 100% ▕████████████████▏  801 B                         \n",
      "pulling ed11eda7790d... 100% ▕████████████████▏   30 B                         \n",
      "pulling 42347cd80dc8... 100% ▕████████████████▏  485 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "success \u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "!ollama pull mistral:instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03e67e17-f389-4066-a359-e1a7f3011697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local LLM: mistral:instruct\n"
     ]
    }
   ],
   "source": [
    "local_llm = \"mistral:instruct\"\n",
    "print(f\"Local LLM: {local_llm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6049f23b-cb63-46ce-8d60-cb4dadbffd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags=['Chroma', 'NomicEmbeddings'] vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x10950f7c0> search_kwargs={}\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain_nomic import NomicEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# Use NomicEmbeddings for embedding\n",
    "\n",
    "embeddings = NomicEmbeddings(model=\"nomic-embed-text-v1.5\", inference_mode=\"remote\")\n",
    "\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"Bella Vista is owned by Antonio Rossi, a renowned chef with over 20 years of experience in the culinary industry. He started Bella Vista to bring authentic Italian flavors to the community.\",\n",
    "        metadata={\"source\": \"restaurant_info.txt\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Bella Vista offers a range of dishes with prices that cater to various budgets. Appetizers start at $8, main courses range from $15 to $35, and desserts are priced between $6 and $12.\",\n",
    "        metadata={\"source\": \"restaurant_info.txt\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Bella Vista is open from Monday to Sunday. Weekday hours are 11:00 AM to 10:00 PM, while weekend hours are extended from 11:00 AM to 11:00 PM.\",\n",
    "        metadata={\"source\": \"restaurant_info.txt\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Bella Vista offers a variety of menus including a lunch menu, dinner menu, and a special weekend brunch menu. The lunch menu features light Italian fare, the dinner menu offers a more extensive selection of traditional and contemporary dishes, and the brunch menu includes both classic breakfast items and Italian specialties.\",\n",
    "        metadata={\"source\": \"restaurant_info.txt\"},\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Create the Chroma vector store with Nomic embeddings\n",
    "db = Chroma.from_documents(docs, embeddings)\n",
    "\n",
    "# Set up the retriever\n",
    "retriever = db.as_retriever()\n",
    "print(retriever)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a891602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'restaurant_info.txt'}, page_content='Bella Vista is open from Monday to Sunday. Weekday hours are 11:00 AM to 10:00 PM, while weekend hours are extended from 11:00 AM to 11:00 PM.'),\n",
       " Document(metadata={'source': 'restaurant_info.txt'}, page_content='Bella Vista offers a variety of menus including a lunch menu, dinner menu, and a special weekend brunch menu. The lunch menu features light Italian fare, the dinner menu offers a more extensive selection of traditional and contemporary dishes, and the brunch menu includes both classic breakfast items and Italian specialties.'),\n",
       " Document(metadata={'source': 'restaurant_info.txt'}, page_content='Bella Vista is owned by Antonio Rossi, a renowned chef with over 20 years of experience in the culinary industry. He started Bella Vista to bring authentic Italian flavors to the community.'),\n",
       " Document(metadata={'source': 'restaurant_info.txt'}, page_content='Bella Vista offers a range of dishes with prices that cater to various budgets. Appetizers start at $8, main courses range from $15 to $35, and desserts are priced between $6 and $12.')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"monday\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fb5d53",
   "metadata": {},
   "source": [
    "## json mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3afd8142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'restaurant_info.txt'}, page_content='Bella Vista offers a range of dishes with prices that cater to various budgets. Appetizers start at $8, main courses range from $15 to $35, and desserts are priced between $6 and $12.'),\n",
       " Document(metadata={'source': 'restaurant_info.txt'}, page_content='Bella Vista offers a variety of menus including a lunch menu, dinner menu, and a special weekend brunch menu. The lunch menu features light Italian fare, the dinner menu offers a more extensive selection of traditional and contemporary dishes, and the brunch menu includes both classic breakfast items and Italian specialties.'),\n",
       " Document(metadata={'source': 'restaurant_info.txt'}, page_content='Bella Vista is owned by Antonio Rossi, a renowned chef with over 20 years of experience in the culinary industry. He started Bella Vista to bring authentic Italian flavors to the community.'),\n",
       " Document(metadata={'source': 'restaurant_info.txt'}, page_content='Bella Vista is open from Monday to Sunday. Weekday hours are 11:00 AM to 10:00 PM, while weekend hours are extended from 11:00 AM to 11:00 PM.')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"dish prices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4904ad",
   "metadata": {},
   "source": [
    "## JSON document grader system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36ec3ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import  Document # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4504f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bella Vista offers a variety of menus including a lunch menu, dinner menu, and a special weekend brunch menu. The lunch menu features light Italian fare, the dinner menu offers a more extensive selection of traditional and contemporary dishes, and the brunch menu includes both classic breakfast items and Italian specialties.\n",
      "{'score': 'yes'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import  PromptTemplate# type: ignore\n",
    "from langchain_community.chat_models import ChatOllama# type: ignore\n",
    "from langchain_core.output_parsers import JsonOutputParser# type: ignore\n",
    "\n",
    "# LLM \n",
    "local_llm = \"mistral:instruct\"\n",
    "llm = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n",
    "\n",
    "# Prompt template\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n\n",
    "Here is the retrieved document:  {{context}} \\n\n",
    "Here is the user question: {question} \\n\n",
    "\n",
    "If the document contains **any** information related to the user question, especially when it comes to time references, operational hours, or related concepts, grade it as relevant. \n",
    "Even if the document only partially mentions the hours of operation, that would be sufficient. \\n\n",
    "If the document contains no relevant information about the question, grade it as irrelevant. \\n\n",
    "Return a binary score 'yes' or 'no' based on whether the document is relevant to the question. \\n  \n",
    "Provide the score as a JSON with a single key 'score' and no explanation.\n",
    "\"\"\",\n",
    "    input_variables=[\"context\", \"question\"],\n",
    ")\n",
    "\n",
    "\n",
    "# Chain to process prompt -> LLM -> JSON output\n",
    "chain = prompt | llm | JsonOutputParser()\n",
    "\n",
    "# Example user question and retrieved documents\n",
    "question = \"how to have tasty food?\"\n",
    "docs = retriever.get_relevant_documents(question)\n",
    "\n",
    "# Ensure we are correctly invoking the chain with the relevant document content\n",
    "score = chain.invoke({\"question\": question, \"context\": docs[0].page_content})\n",
    "print(docs[0].page_content)\n",
    "\n",
    "print(score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e28d3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 'no'}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ccaf74e2",
   "metadata": {},
   "source": [
    "## Graph state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4992e7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"TAVILY_API_KEY\"):\n",
    "    os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Enter your Tavily API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fab21a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_community.tools import TavilySearchResults\n",
    "\n",
    "web_search_tool = TavilySearchResults(k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9cc3f5f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input example: {'input': 'How to bake a cookie?'}\n",
      "Question: How to bake a cookie?\n",
      "Document Content (First 200 chars): Bella Vista offers a variety of menus including a lunch menu, dinner menu, and a special weekend brunch menu. The lunch menu features light Italian fare, the dinner menu offers a more extensive select...\n",
      "Score: {'score': 'no'}\n",
      "Question: How to bake a cookie?\n",
      "Document Content (First 200 chars): Bella Vista offers a range of dishes with prices that cater to various budgets. Appetizers start at $8, main courses range from $15 to $35, and desserts are priced between $6 and $12....\n",
      "Score: {'score': 'no'}\n",
      "Question: How to bake a cookie?\n",
      "Document Content (First 200 chars): Bella Vista is open from Monday to Sunday. Weekday hours are 11:00 AM to 10:00 PM, while weekend hours are extended from 11:00 AM to 11:00 PM....\n",
      "Score: {'score': 'no'}\n",
      "Question: How to bake a cookie?\n",
      "Document Content (First 200 chars): Bella Vista is owned by Antonio Rossi, a renowned chef with over 20 years of experience in the culinary industry. He started Bella Vista to bring authentic Italian flavors to the community....\n",
      "Score: {'score': 'no'}\n",
      "Question: How to bake a cookie?\n",
      "Document Content (First 200 chars): Bella Vista offers a variety of menus including a lunch menu, dinner menu, and a special weekend brunch menu. The lunch menu features light Italian fare, the dinner menu offers a more extensive select...\n",
      "Score: {'score': 'no'}\n",
      "Question: How to bake a cookie?\n",
      "Document Content (First 200 chars): Bella Vista offers a range of dishes with prices that cater to various budgets. Appetizers start at $8, main courses range from $15 to $35, and desserts are priced between $6 and $12....\n",
      "Score: {'score': 'no'}\n",
      "Question: How to bake a cookie?\n",
      "Document Content (First 200 chars): Bella Vista is open from Monday to Sunday. Weekday hours are 11:00 AM to 10:00 PM, while weekend hours are extended from 11:00 AM to 11:00 PM....\n",
      "Score: {'score': 'no'}\n",
      "Question: How to bake a cookie?\n",
      "Document Content (First 200 chars): Bella Vista is owned by Antonio Rossi, a renowned chef with over 20 years of experience in the culinary industry. He started Bella Vista to bring authentic Italian flavors to the community....\n",
      "Score: {'score': 'no'}\n",
      "Question: How to bake a cookie?\n",
      "Document Content (First 200 chars): Bella Vista offers a variety of menus including a lunch menu, dinner menu, and a special weekend brunch menu. The lunch menu features light Italian fare, the dinner menu offers a more extensive select...\n",
      "Score: {'score': 'no'}\n",
      "Question: How to bake a cookie?\n",
      "Document Content (First 200 chars): Bella Vista offers a range of dishes with prices that cater to various budgets. Appetizers start at $8, main courses range from $15 to $35, and desserts are priced between $6 and $12....\n",
      "Score: {'score': 'no'}\n",
      "Question: How to bake a cookie?\n",
      "Document Content (First 200 chars): Bella Vista is open from Monday to Sunday. Weekday hours are 11:00 AM to 10:00 PM, while weekend hours are extended from 11:00 AM to 11:00 PM....\n",
      "Score: {'score': 'no'}\n",
      "Question: How to bake a cookie?\n",
      "Document Content (First 200 chars): Bella Vista is owned by Antonio Rossi, a renowned chef with over 20 years of experience in the culinary industry. He started Bella Vista to bring authentic Italian flavors to the community....\n",
      "Score: {'score': 'no'}\n",
      "Reached retrieval limit. Proceeding to answer generation.\n",
      "State Dict: {'question': 'How to bake a cookie?', 'generation': {'score': 'no'}, 'search': 'Yes', 'documents': [], 'steps': ['retrieve_documents', 'grade_document_retrieval', 'retrieve_documents', 'grade_document_retrieval', 'retrieve_documents', 'grade_document_retrieval', 'generate_answer'], 'retrieval_count': 3}\n",
      "Response: {'response': {'score': 'no'}, 'steps': ['retrieve_documents', 'grade_document_retrieval', 'retrieve_documents', 'grade_document_retrieval', 'retrieve_documents', 'grade_document_retrieval', 'generate_answer']}\n"
     ]
    }
   ],
   "source": [
    "# from typing import List\n",
    "# from typing_extensions import TypedDict\n",
    "# from IPython.display import Image, display\n",
    "# from langchain.schema import Document\n",
    "# from langgraph.graph import START, END, StateGraph\n",
    "\n",
    "\n",
    "\n",
    "# class GraphState(TypedDict):\n",
    "#     \"\"\"\n",
    "#     Represents the state of our graph.\n",
    "\n",
    "#     Attributes:\n",
    "#         question: question\n",
    "#         generation: LLM generation\n",
    "#         search: whether to add search\n",
    "#         documents: list of documents\n",
    "#     \"\"\"\n",
    "\n",
    "#     question: str\n",
    "#     generation: str\n",
    "#     search: str\n",
    "#     documents: List[str]\n",
    "#     steps: List[str]\n",
    "\n",
    "# def retrieve(state):\n",
    "#     \"\"\"\n",
    "#     Retrieve documents\n",
    "\n",
    "#     Args:\n",
    "#         state (dict): The current graph state\n",
    "\n",
    "#     Returns:\n",
    "#         state (dict): New key added to state, documents, that contains retrieved documents\n",
    "#     \"\"\"\n",
    "#     question = state[\"question\"]\n",
    "#     documents = retriever.invoke(question)\n",
    "#     steps = state[\"steps\"]\n",
    "#     steps.append(\"retrieve_documents\")\n",
    "#     return {\"documents\": documents, \"question\": question, \"steps\": steps}\n",
    "\n",
    "\n",
    "# def generate(state):\n",
    "#     \"\"\"\n",
    "#     Generate answer\n",
    "\n",
    "#     Args:\n",
    "#         state (dict): The current graph state\n",
    "\n",
    "#     Returns:\n",
    "#         state (dict): New key added to state, generation, that contains LLM generation\n",
    "#     \"\"\"\n",
    "\n",
    "#     question = state[\"question\"]\n",
    "#     documents = state[\"documents\"]\n",
    "#     generation = chain.invoke({\"documents\": documents, \"question\": question})\n",
    "#     steps = state[\"steps\"]\n",
    "#     steps.append(\"generate_answer\")\n",
    "#     return {\n",
    "#         \"documents\": documents,\n",
    "#         \"question\": question,\n",
    "#         \"generation\": generation,\n",
    "#         \"steps\": steps,\n",
    "#     }\n",
    "\n",
    "\n",
    "# def grade_documents(state):\n",
    "#     question = state[\"question\"]\n",
    "#     documents = state[\"documents\"]\n",
    "#     steps = state[\"steps\"]\n",
    "#     steps.append(\"grade_document_retrieval\")\n",
    "#     filtered_docs = []\n",
    "#     search = \"No\"\n",
    "\n",
    "#     for d in documents:\n",
    "#         try:\n",
    "#             print(f\"Question: {question}\")\n",
    "#             print(f\"Document Content (First 200 chars): {d.page_content[:200]}...\")\n",
    "\n",
    "#             # Use the chain to invoke LLM for grading\n",
    "#             score = chain.invoke({\"question\": question, \"context\": d.page_content})\n",
    "#             print(f\"Score: {score}\")\n",
    "#             if score[\"score\"] == \"yes\":\n",
    "#                 filtered_docs.append(d)\n",
    "#             else:\n",
    "#                 search = \"Yes\"\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error during grading: {e}\")\n",
    "#             search = \"Yes\"\n",
    "#             continue\n",
    "\n",
    "#     return {\n",
    "#         \"documents\": filtered_docs,\n",
    "#         \"question\": question,\n",
    "#         \"search\": search,\n",
    "#         \"steps\": steps,\n",
    "#     }\n",
    "\n",
    "\n",
    "# def web_search(state):\n",
    "#     \"\"\"\n",
    "#     Web search based on the re-phrased question or returns an \"out of context\" message.\n",
    "\n",
    "#     Args:\n",
    "#         state (dict): The current graph state\n",
    "\n",
    "#     Returns:\n",
    "#         state (dict): Updates documents key with a fallback message if the question is out of context.\n",
    "#     \"\"\"\n",
    "\n",
    "#     question = state[\"question\"]\n",
    "#     documents = state.get(\"documents\", [])\n",
    "#     steps = state[\"steps\"]\n",
    "#     steps.append(\"web_search\")\n",
    "\n",
    "#     # Example of a basic check for relevance. If the question is \"out of context\", we skip the search.\n",
    "#     # This check could be based on some condition like keywords, phrase matching, or more advanced logic.\n",
    "#     if is_out_of_context(question):  # Custom function to check relevance\n",
    "#         documents.append(\n",
    "#             Document(page_content=\"The question is out of context. No relevant information found.\", metadata={\"url\": \"N/A\"})\n",
    "#         )\n",
    "#     else:\n",
    "#         # Perform web search if the question is considered relevant\n",
    "#         web_results = web_search_tool.invoke({\"query\": question})\n",
    "#         documents.extend(\n",
    "#             [\n",
    "#                 Document(page_content=d[\"content\"], metadata={\"url\": d[\"url\"]})\n",
    "#                 for d in web_results\n",
    "#             ]\n",
    "#         )\n",
    "\n",
    "#     return {\"documents\": documents, \"question\": question, \"steps\": steps}\n",
    "\n",
    "# # Function to determine if the question is out of context (simple placeholder logic)\n",
    "# def is_out_of_context(question):\n",
    "#     \"\"\"\n",
    "#     Placeholder function to check if the question is out of context.\n",
    "    \n",
    "#     This function can be enhanced with more complex logic based on question analysis,\n",
    "#     keywords, or other criteria.\n",
    "#     \"\"\"\n",
    "#     out_of_context_keywords = [\"irrelevant\", \"out of context\", \"invalid\"]  \n",
    "#     return any(keyword in question.lower() for keyword in out_of_context_keywords)\n",
    "\n",
    "# def decide_to_generate(state):\n",
    "#     \"\"\"\n",
    "#     Determines whether to generate an answer, or re-generate a question.\n",
    "\n",
    "#     Args:\n",
    "#         state (dict): The current graph state\n",
    "\n",
    "#     Returns:\n",
    "#         str: Binary decision for next node to call\n",
    "#     \"\"\"\n",
    "#     search = state[\"search\"]\n",
    "#     if search == \"Yes\":\n",
    "#         return \"search\"\n",
    "#     else:\n",
    "#         return \"generate\"\n",
    "\n",
    "\n",
    "# # Graph\n",
    "# workflow = StateGraph(GraphState)\n",
    "\n",
    "# # Define the nodes\n",
    "# workflow.add_node(\"retrieve\", retrieve)  # retrieve\n",
    "# workflow.add_node(\"grade_documents\", grade_documents)  # grade documents\n",
    "# workflow.add_node(\"generate\", generate)  # generatae\n",
    "# workflow.add_node(\"web_search\", web_search)  # web search\n",
    "\n",
    "# # Build graph\n",
    "# workflow.add_edge(START, \"retrieve\")\n",
    "# workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "# workflow.add_conditional_edges(\n",
    "#     \"grade_documents\",\n",
    "#     decide_to_generate,\n",
    "#     {\n",
    "#         \"search\": \"web_search\",\n",
    "#         \"generate\": \"generate\",\n",
    "#     },\n",
    "# )\n",
    "# workflow.add_edge(\"web_search\", \"generate\")\n",
    "# workflow.add_edge(\"generate\", END)\n",
    "\n",
    "# custom_graph = workflow.compile()\n",
    "\n",
    "# display(Image(custom_graph.get_graph(xray=True).draw_mermaid_png()))\n",
    "\n",
    "\n",
    "\n",
    "# def predict_custom_agent_local_answer(example: dict):\n",
    "#     # Debugging: Log input\n",
    "#     print(\"Input example:\", example)\n",
    "\n",
    "#     # Invoke the custom graph and fetch the state dictionary\n",
    "#     state_dict = custom_graph.invoke(\n",
    "#         {\"question\": example[\"input\"], \"steps\": []}\n",
    "#     )\n",
    "\n",
    "#     # Debugging: Log state_dict output\n",
    "#     print(\"State Dict:\", state_dict)\n",
    "    \n",
    "#     # Validate returned keys\n",
    "#     if \"generation\" not in state_dict or \"steps\" not in state_dict:\n",
    "#         raise KeyError(\"Missing keys in state_dict. Expected 'generation' and 'steps'.\")\n",
    "    \n",
    "#     return {\"response\": state_dict[\"generation\"], \"steps\": state_dict[\"steps\"]}\n",
    "\n",
    "# # Example input\n",
    "# example = {\"input\": \"how to bake a cookie?\"}\n",
    "\n",
    "# try:\n",
    "#     response = predict_custom_agent_local_answer(example)\n",
    "#     print(\"Response:\", response)\n",
    "# except Exception as e:\n",
    "#     print(f\"Error occurred: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ### attempt 2 ##### \n",
    "\n",
    "# from typing import List\n",
    "# from typing_extensions import TypedDict\n",
    "# from langchain.schema import Document\n",
    "# from langgraph.graph import START, END, StateGraph\n",
    "# from IPython.display import Image, display\n",
    "\n",
    "\n",
    "\n",
    "# class GraphState(TypedDict):\n",
    "#     \"\"\"\n",
    "#     Represents the state of our graph.\n",
    "\n",
    "#     Attributes:\n",
    "#         question: question\n",
    "#         generation: LLM generation\n",
    "#         search: whether to add search\n",
    "#         documents: list of documents\n",
    "#         retrieval_count: how many times retrieval has been done\n",
    "#     \"\"\"\n",
    "\n",
    "#     question: str\n",
    "#     generation: str\n",
    "#     search: str\n",
    "#     documents: List[str]\n",
    "#     steps: List[str]\n",
    "#     retrieval_count: int  # Add a retrieval counter\n",
    "\n",
    "\n",
    "# def retrieve(state):\n",
    "#     \"\"\"\n",
    "#     Retrieve documents\n",
    "\n",
    "#     Args:\n",
    "#         state (dict): The current graph state\n",
    "\n",
    "#     Returns:\n",
    "#         state (dict): New key added to state, documents, that contains retrieved documents\n",
    "#     \"\"\"\n",
    "#     question = state[\"question\"]\n",
    "#     documents = retriever.invoke(question)  # Assuming retriever is predefined\n",
    "#     steps = state[\"steps\"]\n",
    "#     steps.append(\"retrieve_documents\")\n",
    "\n",
    "#     # Increment retrieval count each time retrieval is called\n",
    "#     retrieval_count = state.get(\"retrieval_count\", 0) + 1\n",
    "#     state[\"retrieval_count\"] = retrieval_count\n",
    "\n",
    "#     return {\"documents\": documents, \"question\": question, \"steps\": steps, \"retrieval_count\": retrieval_count}\n",
    "\n",
    "\n",
    "# def generate(state):\n",
    "#     \"\"\"\n",
    "#     Generate answer\n",
    "\n",
    "#     Args:\n",
    "#         state (dict): The current graph state\n",
    "\n",
    "#     Returns:\n",
    "#         state (dict): New key added to state, generation, that contains LLM generation\n",
    "#     \"\"\"\n",
    "#     question = state[\"question\"]\n",
    "#     documents = state[\"documents\"]\n",
    "#     generation = chain.invoke({\"documents\": documents, \"question\": question})  # Assuming chain is predefined\n",
    "#     steps = state[\"steps\"]\n",
    "#     steps.append(\"generate_answer\")\n",
    "#     return {\n",
    "#         \"documents\": documents,\n",
    "#         \"question\": question,\n",
    "#         \"generation\": generation,\n",
    "#         \"steps\": steps,\n",
    "#     }\n",
    "\n",
    "\n",
    "# def grade_documents(state):\n",
    "#     \"\"\"\n",
    "#     Grade retrieved documents based on relevance to the question\n",
    "\n",
    "#     Args:\n",
    "#         state (dict): The current graph state\n",
    "\n",
    "#     Returns:\n",
    "#         state (dict): New documents with filtered results and updated state\n",
    "#     \"\"\"\n",
    "#     question = state[\"question\"]\n",
    "#     documents = state[\"documents\"]\n",
    "#     steps = state[\"steps\"]\n",
    "#     steps.append(\"grade_document_retrieval\")\n",
    "\n",
    "#     filtered_docs = []\n",
    "#     search = \"No\"  # Default to No search needed\n",
    "\n",
    "#     for d in documents:\n",
    "#         try:\n",
    "#             print(f\"Question: {question}\")\n",
    "#             print(f\"Document Content (First 200 chars): {d.page_content[:200]}...\")\n",
    "\n",
    "#             # Use the chain to invoke LLM for grading\n",
    "#             score = chain.invoke({\"question\": question, \"context\": d.page_content})\n",
    "#             print(f\"Score: {score}\")\n",
    "\n",
    "#             # Add the document if relevant\n",
    "#             if score[\"score\"] == \"yes\":\n",
    "#                 filtered_docs.append(d)\n",
    "#             else:\n",
    "#                 search = \"Yes\"  # Mark as needing web search if irrelevant\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error during grading: {e}\")\n",
    "#             search = \"Yes\"  # In case of error, flag for a web search\n",
    "#             continue\n",
    "\n",
    "#     return {\n",
    "#         \"documents\": filtered_docs,\n",
    "#         \"question\": question,\n",
    "#         \"search\": search,\n",
    "#         \"steps\": steps,\n",
    "#     }\n",
    "\n",
    "\n",
    "# def decide_to_generate(state):\n",
    "#     \"\"\"\n",
    "#     Decides whether to generate an answer, or if another retrieval is needed.\n",
    "    \n",
    "#     Stops after a set number of retrieval attempts.\n",
    "\n",
    "#     Args:\n",
    "#         state (dict): The current graph state\n",
    "\n",
    "#     Returns:\n",
    "#         str: The next node in the process (\"generate\" or \"retrieve\")\n",
    "#     \"\"\"\n",
    "#     retrieval_count = state.get(\"retrieval_count\", 0)\n",
    "#     search = state[\"search\"]\n",
    "\n",
    "#     if retrieval_count >= 3:  # Limit retrieval to 3 times\n",
    "#         print(\"Reached retrieval limit. Proceeding to answer generation.\")\n",
    "#         return \"generate\"  # After 3 retrieval attempts, move to generation\n",
    "\n",
    "#     if search == \"Yes\":\n",
    "#         return \"retrieve\"  # If search is needed, go back to retrieve\n",
    "#     else:\n",
    "#         return \"generate\"  # If no search needed, generate the answer\n",
    "\n",
    "\n",
    "# # Graph definition\n",
    "# workflow = StateGraph(GraphState)\n",
    "\n",
    "# # Define the nodes\n",
    "# workflow.add_node(\"retrieve\", retrieve)  # Node to retrieve documents\n",
    "# workflow.add_node(\"grade_documents\", grade_documents)  # Node to grade retrieved documents\n",
    "# workflow.add_node(\"generate\", generate)  # Node to generate the answer\n",
    "\n",
    "# # Build the graph structure\n",
    "# workflow.add_edge(START, \"retrieve\")\n",
    "# workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "# workflow.add_conditional_edges(\n",
    "#     \"grade_documents\",\n",
    "#     decide_to_generate,  # Decision function for whether to generate or retrieve more documents\n",
    "#     {\n",
    "#         \"retrieve\": \"retrieve\",  # If more docs are needed, go back to retrieve\n",
    "#         \"generate\": \"generate\",  # Otherwise, generate an answer\n",
    "#     },\n",
    "# )\n",
    "# workflow.add_edge(\"generate\", END)\n",
    "\n",
    "# # Compile and visualize the workflow\n",
    "# custom_graph = workflow.compile()\n",
    "\n",
    "# # Display the graph visualization\n",
    "# display(Image(custom_graph.get_graph(xray=True).draw_mermaid_png()))\n",
    "\n",
    "\n",
    "# def predict_custom_agent_local_answer(example: dict):\n",
    "#     \"\"\"\n",
    "#     Make a prediction using the custom agent workflow.\n",
    "    \n",
    "#     Args:\n",
    "#         example (dict): Input dictionary with the question\n",
    "        \n",
    "#     Returns:\n",
    "#         dict: Response and steps taken in the graph\n",
    "#     \"\"\"\n",
    "#     # Debugging: Log input\n",
    "#     print(\"Input example:\", example)\n",
    "\n",
    "#     # Invoke the custom graph and fetch the state dictionary\n",
    "#     state_dict = custom_graph.invoke(\n",
    "#         {\"question\": example[\"input\"], \"steps\": [], \"retrieval_count\": 0}  # Start with 0 retrieval attempts\n",
    "#     )\n",
    "\n",
    "#     # Debugging: Log state_dict output\n",
    "#     print(\"State Dict:\", state_dict)\n",
    "    \n",
    "#     # Validate returned keys\n",
    "#     if \"generation\" not in state_dict or \"steps\" not in state_dict:\n",
    "#         raise KeyError(\"Missing keys in state_dict. Expected 'generation' and 'steps'.\")\n",
    "    \n",
    "#     return {\"response\": state_dict[\"generation\"], \"steps\": state_dict[\"steps\"]}\n",
    "\n",
    "\n",
    "# # Example input for testing\n",
    "# example = {\"input\": \"How to bake a cookie?\"}\n",
    "\n",
    "# # Call the function and print the response\n",
    "# try:\n",
    "#     response = predict_custom_agent_local_answer(example)\n",
    "#     print(\"Response:\", response)\n",
    "# except Exception as e:\n",
    "#     print(f\"Error occurred: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8c7871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import List\n",
    "# from pydantic import BaseModel, Field\n",
    "# from langchain.schema import Document\n",
    "# from IPython.display import Image, display\n",
    "# from langgraph.graph import START, END, StateGraph\n",
    "\n",
    "# class AgentState(BaseModel):\n",
    "#     question: str\n",
    "#     documents: List[Document] = []\n",
    "#     grades: List[str] = []\n",
    "#     search: str = \"No\"\n",
    "#     steps: List[str] = []\n",
    "#     retrieval_count: int = 0\n",
    "#     topic: str = \"\"\n",
    "#     response: str = \"\"\n",
    "\n",
    "# class GradeDocuments(BaseModel):\n",
    "#     score: str = Field(\n",
    "#         description=\"Documents are relevant to the question, 'Yes' or 'No'\"\n",
    "#     )\n",
    "\n",
    "# def topic_decision(state: AgentState):\n",
    "#     \"\"\"\n",
    "#     Decide if the question is on-topic or off-topic.\n",
    "\n",
    "#     Args:\n",
    "#         state (AgentState): Current graph state.\n",
    "\n",
    "#     Returns:\n",
    "#         AgentState: Updated state with topic decision.\n",
    "#     \"\"\"\n",
    "#     question = state.question\n",
    "\n",
    "#     # Simple heuristic for topic decision (replace with an LLM for better evaluation)\n",
    "#     off_topic_keywords = [\"violate\", \"bake\", \"unrelated\"]\n",
    "#     if any(keyword in question.lower() for keyword in off_topic_keywords):\n",
    "#         state.topic = \"off_topic\"\n",
    "#         state.response = \"Your question is off-topic or violates guidelines.\"\n",
    "#     else:\n",
    "#         state.topic = \"on_topic\"\n",
    "\n",
    "#     state.steps.append(\"topic_decision\")\n",
    "#     return state\n",
    "\n",
    "# def document_grader(state: AgentState):\n",
    "#     \"\"\"\n",
    "#     Grade the relevance of retrieved documents.\n",
    "\n",
    "#     Args:\n",
    "#         state (AgentState): Current graph state.\n",
    "\n",
    "#     Returns:\n",
    "#         AgentState: Updated state with graded documents.\n",
    "#     \"\"\"\n",
    "#     docs = state.documents\n",
    "#     question = state.question\n",
    "\n",
    "#     system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question.\\n\n",
    "#         If the document contains keyword(s) or semantic meaning related to the question, grade it as relevant.\\n\n",
    "#         Give a binary score 'Yes' or 'No' score to indicate whether the document is relevant to the question.\"\"\"\n",
    "\n",
    "#     # Mock grader implementation\n",
    "#     for doc in docs:\n",
    "#         if any(keyword in doc.page_content.lower() for keyword in question.lower().split()):\n",
    "#             state.grades.append(\"Yes\")\n",
    "#         else:\n",
    "#             state.grades.append(\"No\")\n",
    "\n",
    "#     state.steps.append(\"document_grader\")\n",
    "#     return state\n",
    "\n",
    "# def decide_next_action(state: AgentState):\n",
    "#     \"\"\"\n",
    "#     Decide whether to rewrite the query or generate the answer.\n",
    "\n",
    "#     Args:\n",
    "#         state (AgentState): Current graph state.\n",
    "\n",
    "#     Returns:\n",
    "#         str: Next step, either \"rewrite_query\" or \"generate_answer\".\n",
    "#     \"\"\"\n",
    "#     if all(grade == \"No\" for grade in state.grades):\n",
    "#         return \"rewrite_query\"\n",
    "#     return \"generate_answer\"\n",
    "\n",
    "# def rewrite_query(state: AgentState):\n",
    "#     \"\"\"\n",
    "#     Rewrite the query for better document retrieval.\n",
    "\n",
    "#     Args:\n",
    "#         state (AgentState): Current graph state.\n",
    "\n",
    "#     Returns:\n",
    "#         AgentState: Updated state with rewritten query.\n",
    "#     \"\"\"\n",
    "#     state.question = f\"Refined: {state.question}\"\n",
    "#     state.steps.append(\"rewrite_query\")\n",
    "#     return state\n",
    "\n",
    "# def generate_answer(state: AgentState):\n",
    "#     \"\"\"\n",
    "#     Generate the answer based on relevant documents.\n",
    "\n",
    "#     Args:\n",
    "#         state (AgentState): Current graph state.\n",
    "\n",
    "#     Returns:\n",
    "#         AgentState: Updated state with generated response.\n",
    "#     \"\"\"\n",
    "#     if state.documents:\n",
    "#         state.response = f\"Answer generated from {len(state.documents)} relevant document(s).\"\n",
    "#     else:\n",
    "#         state.response = \"No relevant documents found.\"\n",
    "\n",
    "#     state.steps.append(\"generate_answer\")\n",
    "#     return state\n",
    "\n",
    "# # Graph definition\n",
    "# workflow = StateGraph(AgentState)\n",
    "\n",
    "# # Add nodes\n",
    "# workflow.add_node(\"topic_decision\", topic_decision)\n",
    "# workflow.add_node(\"retrieve\", lambda state: state)  # Mock retrieval for simplicity\n",
    "# workflow.add_node(\"document_grader\", document_grader)\n",
    "# workflow.add_node(\"rewrite_query\", rewrite_query)\n",
    "# workflow.add_node(\"generate_answer\", generate_answer)\n",
    "\n",
    "# # Add edges\n",
    "# workflow.add_edge(START, \"topic_decision\")\n",
    "# workflow.add_conditional_edges(\n",
    "#     \"topic_decision\",\n",
    "#     lambda state: {\"off_topic_response\": state.topic == \"off_topic\", \"retrieve\": state.topic == \"on_topic\"},\n",
    "#     {\"off_topic_response\": END, \"retrieve\": \"retrieve\"},\n",
    "# )\n",
    "# workflow.add_edge(\"retrieve\", \"document_grader\")\n",
    "# workflow.add_conditional_edges(\n",
    "#     \"document_grader\",\n",
    "#     decide_next_action,\n",
    "#     {\"rewrite_query\": \"rewrite_query\", \"generate_answer\": \"generate_answer\"},\n",
    "# )\n",
    "# workflow.add_edge(\"rewrite_query\", \"retrieve\")\n",
    "# workflow.add_edge(\"generate_answer\", END)\n",
    "\n",
    "\n",
    "# custom_graph = workflow.compile()\n",
    "# # Example usage\n",
    "\n",
    "# # Compile and visualize the workflow\n",
    "# # Display the graph visualization\n",
    "# # Uncomment the next line if graph rendering is needed\n",
    "# display(Image(custom_graph.get_graph(xray=True).draw_mermaid_png()))\n",
    "\n",
    "# def predict_custom_agent_local_answer(example: dict):\n",
    "#     \"\"\"\n",
    "#     Make a prediction using the custom agent workflow.\n",
    "    \n",
    "#     Args:\n",
    "#         example (dict): Input dictionary with the question\n",
    "        \n",
    "#     Returns:\n",
    "#         dict: Response and steps taken in the graph\n",
    "#     \"\"\"\n",
    "#     # Debugging: Log input\n",
    "#     print(\"Input example:\", example)\n",
    "\n",
    "#     # Invoke the custom graph and fetch the state dictionary\n",
    "#     state_dict = custom_graph.invoke(\n",
    "#         {\"question\": example[\"input\"], \"steps\": [], \"retrieval_count\": 0}  # Start with 0 retrieval attempts\n",
    "#     )\n",
    "\n",
    "#     # Debugging: Log state_dict output\n",
    "#     print(\"State Dict:\", state_dict)\n",
    "    \n",
    "#     # Validate returned keys\n",
    "#     if \"response\" not in state_dict or \"steps\" not in state_dict:\n",
    "#         raise KeyError(\"Missing keys in state_dict. Expected 'response' and 'steps'.\")\n",
    "    \n",
    "#     return {\"response\": state_dict[\"response\"], \"steps\": state_dict[\"steps\"]}\n",
    "\n",
    "# # Example input for testing\n",
    "# example = {\"input\": \"How to bake a cookie?\"}\n",
    "\n",
    "# # Call the function and print the response\n",
    "# try:\n",
    "#     response = predict_custom_agent_local_answer(example)\n",
    "#     print(\"Response:\", response)\n",
    "# except Exception as e:\n",
    "#     print(f\"Error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a991992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: {'response': None, 'steps': ['topic_decision', 'retrieve_documents', 'grade_document_retrieval', 'generate_answer']}\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "\n",
    "from typing import List, TypedDict\n",
    "\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    generation: str\n",
    "    topic_status: str\n",
    "    documents: List[Document]\n",
    "    steps: List[str]\n",
    "\n",
    "# Topic Decision Prompt\n",
    "topic_decision_prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a topic classifier evaluating whether a question is appropriate and on-topic.\n",
    "\n",
    "Evaluate the following question: {question}\n",
    "\n",
    "Guidelines for off-topic classification:\n",
    "1. Explicit harmful or offensive content\n",
    "2. Completely unrelated to restaurant or food context\n",
    "3. Requests for personal or private information\n",
    "4. Inappropriate or provocative questions\n",
    "\n",
    "Return a JSON with:\n",
    "- 'status': 'on-topic' or 'off-topic'\n",
    "- 'reason': Brief explanation of the decision\n",
    "\"\"\",\n",
    "    input_variables=[\"question\"]\n",
    ")\n",
    "\n",
    "# Relevance Grading Prompt\n",
    "relevance_prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a grader assessing relevance of a retrieved document to a user question.\n",
    "\n",
    "Here is the retrieved document: {context}\n",
    "Here is the user question: {question}\n",
    "\n",
    "If the document contains ANY information related to the user question, grade it as relevant.\n",
    "Return a JSON with a single key 'score' as 'yes' or 'no'.\n",
    "\"\"\",\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "# Chains\n",
    "topic_decision_chain = topic_decision_prompt | llm | JsonOutputParser()\n",
    "relevance_chain = relevance_prompt | llm | JsonOutputParser()\n",
    "\n",
    "def topic_decision(state):\n",
    "    \"\"\"\n",
    "    Decide if the question is on-topic or off-topic\n",
    "    \"\"\"\n",
    "    question = state[\"question\"]\n",
    "    steps = state.get(\"steps\", [])\n",
    "    steps.append(\"topic_decision\")\n",
    "\n",
    "    # Invoke topic decision chain\n",
    "    result = topic_decision_chain.invoke({\"question\": question})\n",
    "    \n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"topic_status\": result['status'],\n",
    "        \"steps\": steps\n",
    "    }\n",
    "\n",
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    Retrieve documents if on-topic\n",
    "    \"\"\"\n",
    "    question = state[\"question\"]\n",
    "    steps = state.get(\"steps\", [])\n",
    "    steps.append(\"retrieve_documents\")\n",
    "\n",
    "    documents = retriever.invoke(question)\n",
    "    return {\n",
    "        \"documents\": documents, \n",
    "        \"question\": question, \n",
    "        \"steps\": steps\n",
    "    }\n",
    "\n",
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    Grade retrieved documents based on relevance\n",
    "    \"\"\"\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    steps = state.get(\"steps\", [])\n",
    "    steps.append(\"grade_document_retrieval\")\n",
    "\n",
    "    filtered_docs = []\n",
    "    for doc in documents:\n",
    "        score = relevance_chain.invoke({\"question\": question, \"context\": doc.page_content})\n",
    "        if score[\"score\"] == \"yes\":\n",
    "            filtered_docs.append(doc)\n",
    "\n",
    "    return {\n",
    "        \"documents\": filtered_docs,\n",
    "        \"question\": question,\n",
    "        \"steps\": steps\n",
    "    }\n",
    "\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer or return None\n",
    "    \"\"\"\n",
    "    documents = state.get(\"documents\", [])\n",
    "    topic_status = state.get(\"topic_status\", \"off-topic\")\n",
    "    steps = state.get(\"steps\", [])\n",
    "    steps.append(\"generate_answer\")\n",
    "\n",
    "    # If no documents or off-topic, return None\n",
    "    if not documents or topic_status == \"off-topic\":\n",
    "        return {\n",
    "            \"generation\": None,\n",
    "            \"steps\": steps\n",
    "        }\n",
    "\n",
    "    # Generate response using Mistral\n",
    "    question = state[\"question\"]\n",
    "    context = \"\\n\".join([doc.page_content for doc in documents])\n",
    "    generation_prompt = f\"\"\"Given the following context:\n",
    "{context}\n",
    "\n",
    "Please answer the question: {question}\n",
    "\"\"\"\n",
    "    generation = llm.invoke(generation_prompt).content\n",
    "\n",
    "    return {\n",
    "        \"generation\": generation,\n",
    "        \"documents\": documents,\n",
    "        \"question\": question,\n",
    "        \"steps\": steps\n",
    "    }\n",
    "\n",
    "# Workflow Graph\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Define nodes\n",
    "workflow.add_node(\"topic_decision\", topic_decision)\n",
    "workflow.add_node(\"retrieve\", retrieve)\n",
    "workflow.add_node(\"grade_documents\", grade_documents)\n",
    "workflow.add_node(\"generate\", generate)\n",
    "\n",
    "# Define edges\n",
    "workflow.add_edge(START, \"topic_decision\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"topic_decision\",\n",
    "    lambda state: \"generate\" if state[\"topic_status\"] == \"off-topic\" else \"retrieve\",\n",
    "    {\n",
    "        \"generate\": \"generate\",\n",
    "        \"retrieve\": \"retrieve\"\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_edge(\"grade_documents\", \"generate\")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "\n",
    "# Compile the workflow\n",
    "custom_graph = workflow.compile()\n",
    "\n",
    "def predict_custom_agent_local_answer(example: dict):\n",
    "    \"\"\"\n",
    "    Make a prediction using the custom agent workflow\n",
    "    \"\"\"\n",
    "    state_dict = custom_graph.invoke({\n",
    "        \"question\": example[\"input\"], \n",
    "        \"steps\": [], \n",
    "        \"topic_status\": \"pending\"\n",
    "    })\n",
    "\n",
    "    return {\n",
    "        \"response\": state_dict.get(\"generation\"),\n",
    "        \"steps\": state_dict.get(\"steps\", [])\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "example = {\"input\": \"what is bella?\"}\n",
    "response = predict_custom_agent_local_answer(example)\n",
    "print(\"Response:\", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
